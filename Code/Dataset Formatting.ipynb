{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f337fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a60ce34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower and Tokenize the text. No SpaCY tokenization\n",
    "def tokenize_text(review_text):\n",
    "    \n",
    "    text = review_text.lower()\n",
    "    \n",
    "    text = text.encode('ascii', 'ignore').decode('ascii')\n",
    "    \n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    tokens = text.split()\n",
    "    \n",
    "    if len(tokens) >= 508:\n",
    "        tokens = tokens[:508]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41e0f967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"i'm\", 'having', 'issues.', 'yesterday', 'i', 'rebooked', 'for', '24', 'hours', 'after', 'i', 'was', 'supposed', 'to', 'fly,', 'now', 'i', \"can't\", 'log', 'on', '&', 'check', 'in.', 'can', 'you', 'help?']\n"
     ]
    }
   ],
   "source": [
    "print(tokenize_text(\"@united I'm having issues. Yesterday I rebooked for 24 hours after I was supposed to fly, now I can't log on &amp; check in. Can you help?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76226162",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = './dataset/Full Dataset/'\n",
    "experiment_path = './dataset/Experiment/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9d09bc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Training Samples: 145381\n",
      "Total Valid Samples: 8080\n",
      "Total Test Samples: 8080\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pd.read_json (root_path + 'train.json', encoding = 'utf-8')\n",
    "valid_dataset = pd.read_json (root_path + 'val.json', encoding = 'utf-8')\n",
    "test_dataset = pd.read_json (root_path + 'test.json', encoding = 'utf-8')\n",
    "\n",
    "print('Total Training Samples:', len(train_dataset))\n",
    "print('Total Valid Samples:', len(valid_dataset))\n",
    "print('Total Test Samples:', len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2781f3db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_review_posted                                                         51\n",
       "user_total_helpful_votes                                                   43\n",
       "expertise                                                            0.003983\n",
       "user_cities_visited                                                        42\n",
       "review_days                                                          0.243702\n",
       "helpful_class                                                               0\n",
       "review_text                 We stayed here for three nights and would defi...\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a488ec9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_fomat(dataset):\n",
    "  \n",
    "  save_list = []\n",
    "\n",
    "  for index, row in dataset.iterrows():\n",
    "    temp_dict = {}\n",
    "    temp_dict[\"expertise\"] = row[\"expertise\"]\n",
    "    temp_dict[\"review_days\"] = row[\"review_days\"]\n",
    "\n",
    "    temp_dict[\"helpful_class\"] = row[\"helpful_class\"]\n",
    "    temp_dict[\"review_text\"] = tokenize_text(row[\"review_text\"])\n",
    "\n",
    "    save_list.append(temp_dict)\n",
    "  \n",
    "  return save_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c28889",
   "metadata": {},
   "source": [
    "### Train Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe67339",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_save_list = data_fomat(train_dataset)\n",
    "\n",
    "with open(experiment_path + 'train.json', 'w', encoding='utf-8') as file:\n",
    "  for sample in train_save_list:\n",
    "    file.write(json.dumps(sample))\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a6522",
   "metadata": {},
   "source": [
    "### Valid Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e87e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_save_list = data_fomat(valid_dataset)\n",
    "\n",
    "with open(experiment_path + 'valid.json', 'w', encoding='utf-8') as file:\n",
    "  for sample in valid_save_list:\n",
    "    file.write(json.dumps(sample))\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360b4517",
   "metadata": {},
   "source": [
    "### Test Data Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4e8ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_save_list = data_fomat(test_dataset)\n",
    "\n",
    "with open(experiment_path + 'test.json', 'w', encoding='utf-8') as file:\n",
    "  for sample in test_save_list:\n",
    "    file.write(json.dumps(sample))\n",
    "    file.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691744b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
